{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate a simple speech dataset\n",
    "def generate_speech_data():\n",
    "    '''\n",
    "    Make sure you have a file path set that contains the files you want to use.\n",
    "    '''\n",
    "    speech_samples = [\"recognize speech\", \"transcribe spoken words\", \"LSTMs in speech analysis\"]\n",
    "    labels = [\"recognize speech\", \"transcribe spoken words\", \"LSTMs in speech analysis\"]\n",
    "\n",
    "    for i, sample in enumerate(speech_samples):\n",
    "        file_path = f\"speech_sample_{i}.wav\"\n",
    "        audio_data, _ = librosa.load(sf.SoundFile(file_path))\n",
    "        sf.write(file_path, audio_data, 16000, subtype='PCM_16')\n",
    "\n",
    "    return speech_samples, labels\n",
    "\n",
    "# Load and process speech dataset\n",
    "speech_samples, labels = generate_speech_data()\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(speech_samples)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = tokenizer.texts_to_sequences(speech_samples)\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "X_train_speech = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "y_train_speech = tokenizer.texts_to_matrix(labels, mode='binary')\n",
    "\n",
    "# Build and train the LSTM model\n",
    "model_speech = Sequential()\n",
    "model_speech.add(LSTM(32, activation=\"relu\", input_shape=(max_sequence_length,)))\n",
    "model_speech.add(Dense(total_words, activation=\"softmax\"))\n",
    "model_speech.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_speech = model_speech.fit(X_train_speech, y_train_speech, epochs=20, batch_size=1, verbose=1)\n",
    "\n",
    "# Generate sample output\n",
    "seed_speech = \"LSTMs in\"\n",
    "seed_sequence = tokenizer.texts_to_sequences([seed_speech])[0]\n",
    "seed_sequence = tf.keras.preprocessing.sequence.pad_sequences([seed_sequence], maxlen=max_sequence_length, padding='pre')\n",
    "predicted_probs_speech = model_speech.predict(seed_sequence)[0]\n",
    "predicted_index_speech = np.argmax(predicted_probs_speech)\n",
    "output_speech = [word for word, index in tokenizer.word_index.items() if index == predicted_index_speech][0]\n",
    "print(\"Generated Output:\", seed_speech + \" \" + output_speech)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
